"""
RAG Kubernetes Test - –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è ChromaDB vs FAISS –Ω–∞ Kubernetes –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—ó
"""
import os
import time
import json
from datetime import datetime
from typing import List, Dict, Any
from pathlib import Path

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI

from utils import create_vector_store
from utils.pdf_processor import PDFProcessor
from utils.base_vector_store import BaseVectorStore

load_dotenv()


# ============================================================================
# CONFIGURATION
# ============================================================================

class TestConfig:
    """–ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è"""

    # –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ chunking
    CHUNK_SIZE = 1000  # –†–æ–∑–º—ñ—Ä chunk'—ñ–≤ –¥–ª—è –ø–æ–¥—ñ–ª—É –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤
    CHUNK_OVERLAP = 200  # –ü–µ—Ä–µ–∫—Ä–∏—Ç—Ç—è –º—ñ–∂ chunk'–∞–º–∏

    # –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ –ø–æ—à—É–∫—É
    TOP_K = 4  # –ö—ñ–ª—å–∫—ñ—Å—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤ –¥–ª—è –≤–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è
    ALPHA = 0.5  # MMR diversity (0.0 = —Ç—ñ–ª—å–∫–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ñ—Å—Ç—å, 1.0 = —Ç—ñ–ª—å–∫–∏ —Ä—ñ–∑–Ω–æ–º–∞–Ω—ñ—Ç–Ω—ñ—Å—Ç—å)

    # –®–ª—è—Ö–∏
    PDF_FOLDER = "data/pdf"  # –ü–∞–ø–∫–∞ –∑ PDF –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏
    RESULTS_FOLDER = "test_results"  # –ü–∞–ø–∫–∞ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤

    # LLM –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –≤—ñ–¥–ø–æ–≤—ñ–¥–µ–π
    LLM_MODEL = "gpt-4o-mini"
    LLM_TEMPERATURE = 0.7


# ============================================================================
# KUBERNETES QUESTIONS
# ============================================================================

KUBERNETES_QUESTIONS = [
    "What is Kubernetes?",
    "What is a Pod in Kubernetes?",
    "What is the difference between a Pod and a Container?",
    "What is a Kubernetes cluster?",
    "What is a Node in Kubernetes?",
    "What is the role of the control plane?",
    "What is kubectl?",
    "What is a namespace in Kubernetes?",
    "What is the purpose of etcd in Kubernetes?",
    "What is a Kubernetes API server?",
    "What is a Deployment in Kubernetes?",
    "What is a ReplicaSet?",
    "How do you scale a Deployment?",
    "What is a StatefulSet?",
    "What is a DaemonSet?",
    "What is the difference between Deployment and StatefulSet?",
    "What is a Job in Kubernetes?",
    "What is a CronJob?",
    "How do you perform a rolling update?",
    "What is a rollback in Kubernetes?",
    "What is a Service in Kubernetes?",
    "What are the types of Kubernetes Services?",
    "What is a ClusterIP service?",
    "What is a NodePort service?",
    "What is a LoadBalancer service?",
    "What is an Ingress?",
    "What is the difference between Service and Ingress?",
    "How do Pods communicate with each other?",
    "What is a NetworkPolicy?",
    "What is DNS in Kubernetes?",
    "How do you implement zero-downtime deployments in Kubernetes?",
    "What are the best practices for managing secrets in Kubernetes production environments?",
    "How do you implement auto-scaling for applications in Kubernetes?",
    "What is the recommended approach for implementing health checks and readiness probes?",
    "How do you implement persistent storage for databases in Kubernetes?",
    "What are the strategies for implementing multi-tenancy in a Kubernetes cluster?",
    "How do you implement monitoring and logging in a Kubernetes production environment?",
    "What are the best practices for resource limits and requests configuration?",
    "How do you implement blue-green deployment strategy in Kubernetes?",
    "What are the security best practices for hardening a production Kubernetes cluster?",
]


# ============================================================================
# RAG TESTER CLASS
# ============================================================================

class RAGKubernetesTester:
    """–ö–ª–∞—Å –¥–ª—è —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è RAG —Å–∏—Å—Ç–µ–º –Ω–∞ Kubernetes –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—ó"""

    def __init__(self, config: TestConfig):
        self.config = config
        self.pdf_processor = PDFProcessor(
            chunk_size=config.CHUNK_SIZE,
            chunk_overlap=config.CHUNK_OVERLAP
        )
        self.llm = ChatOpenAI(
            model=config.LLM_MODEL,
            temperature=config.LLM_TEMPERATURE
        )

        # –°—Ç–≤–æ—Ä—é—î–º–æ –ø–∞–ø–∫–∏
        os.makedirs(config.PDF_FOLDER, exist_ok=True)
        os.makedirs(config.RESULTS_FOLDER, exist_ok=True)

        # Vector stores
        self.chromadb = None
        self.faiss = None

    def load_pdfs_to_stores(self, force_reload: bool = False):
        """
        –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î PDF –¥–æ–∫—É–º–µ–Ω—Ç–∏ –¥–æ –æ–±–æ—Ö vector stores

        Args:
            force_reload: –ü—Ä–∏–º—É—Å–æ–≤–æ –ø–µ—Ä–µ–∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –Ω–∞–≤—ñ—Ç—å —è–∫—â–æ –≤–∂–µ —î –¥–æ–∫—É–º–µ–Ω—Ç–∏
        """
        print("\n" + "="*80)
        print("üìÑ –ó–ê–í–ê–ù–¢–ê–ñ–ï–ù–ù–Ø PDF –î–û–ö–£–ú–ï–ù–¢–Ü–í")
        print("="*80 + "\n")

        # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É—î–º–æ vector stores
        print("–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è vector stores...")
        self.chromadb = create_vector_store("chromadb", collection_name="kubernetes_docs")
        self.faiss = create_vector_store("faiss", index_name="kubernetes_docs")
        print("‚úì Vector stores —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–æ\n")

        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ –≤–∂–µ —î –¥–æ–∫—É–º–µ–Ω—Ç–∏
        chromadb_count = self.chromadb.get_collection_count()
        faiss_count = self.faiss.get_collection_count()

        if not force_reload and chromadb_count > 0 and faiss_count > 0:
            print(f"‚úì –î–æ–∫—É–º–µ–Ω—Ç–∏ –≤–∂–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω—ñ:")
            print(f"  ChromaDB: {chromadb_count} –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤")
            print(f"  FAISS: {faiss_count} –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤")
            print("\n  –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ —ñ—Å–Ω—É—é—á—ñ –¥–∞–Ω—ñ. –î–ª—è –ø–µ—Ä–µ–∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑–∞–ø—É—Å—Ç—ñ—Ç—å –∑ force_reload=True\n")
            return

        # –ó–Ω–∞—Ö–æ–¥–∏–º–æ PDF —Ñ–∞–π–ª–∏
        pdf_folder = Path(self.config.PDF_FOLDER)
        pdf_files = list(pdf_folder.glob("*.pdf"))

        if not pdf_files:
            print(f"‚ö†Ô∏è  –£–í–ê–ì–ê: –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ PDF —Ñ–∞–π–ª—ñ–≤ —É –ø–∞–ø—Ü—ñ '{self.config.PDF_FOLDER}'")
            print(f"   –ë—É–¥—å –ª–∞—Å–∫–∞, –¥–æ–¥–∞–π—Ç–µ Kubernetes PDF –¥–æ–∫—É–º–µ–Ω—Ç–∏ —É —Ü—é –ø–∞–ø–∫—É\n")
            return

        print(f"–ó–Ω–∞–π–¥–µ–Ω–æ {len(pdf_files)} PDF —Ñ–∞–π–ª—ñ–≤:\n")
        for pdf_file in pdf_files:
            print(f"  ‚Ä¢ {pdf_file.name}")
        print()

        # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ —Ç–∞ –æ–±—Ä–æ–±–ª—è—î–º–æ PDF
        all_chunks = []
        for i, pdf_path in enumerate(pdf_files, 1):
            print(f"[{i}/{len(pdf_files)}] –û–±—Ä–æ–±–∫–∞: {pdf_path.name}")
            try:
                chunks = self.pdf_processor.load_pdf(str(pdf_path))
                all_chunks.extend(chunks)
                print(f"   ‚úì {len(chunks)} chunk'—ñ–≤ —Å—Ç–≤–æ—Ä–µ–Ω–æ")
            except Exception as e:
                print(f"   ‚úó –ü–æ–º–∏–ª–∫–∞: {e}")

        if not all_chunks:
            print("\n‚ö†Ô∏è  –ù–µ –≤–¥–∞–ª–æ—Å—è –æ–±—Ä–æ–±–∏—Ç–∏ –∂–æ–¥–µ–Ω –¥–æ–∫—É–º–µ–Ω—Ç\n")
            return

        print(f"\nüìä –í—Å—å–æ–≥–æ chunk'—ñ–≤ —Å—Ç–≤–æ—Ä–µ–Ω–æ: {len(all_chunks)}")
        print(f"   Chunk size: {self.config.CHUNK_SIZE}")
        print(f"   Chunk overlap: {self.config.CHUNK_OVERLAP}\n")

        # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –¥–æ ChromaDB
        print("–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–æ ChromaDB...")
        start_time = time.time()
        self.chromadb.add_documents(all_chunks)
        chromadb_time = time.time() - start_time
        print(f"‚úì ChromaDB: {len(all_chunks)} –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤ –∑–∞ {chromadb_time:.2f}—Å\n")

        # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –¥–æ FAISS
        print("–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–æ FAISS...")
        start_time = time.time()
        self.faiss.add_documents(all_chunks)
        faiss_time = time.time() - start_time
        print(f"‚úì FAISS: {len(all_chunks)} –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤ –∑–∞ {faiss_time:.2f}—Å\n")

        print("="*80)
        print(f"‚úì –î–û–ö–£–ú–ï–ù–¢–ò –£–°–ü–Ü–®–ù–û –ó–ê–í–ê–ù–¢–ê–ñ–ï–ù–Ü")
        print(f"  ChromaDB: {chromadb_time:.2f}—Å ({len(all_chunks)/chromadb_time:.1f} chunk/—Å)")
        print(f"  FAISS: {faiss_time:.2f}—Å ({len(all_chunks)/faiss_time:.1f} chunk/—Å)")
        print("="*80 + "\n")

    def retrieve_and_answer(
        self,
        vector_store: BaseVectorStore,
        question: str
    ) -> Dict[str, Any]:
        """
        –í–∏—Ç—è–≥—É—î –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ç–∞ –≥–µ–Ω–µ—Ä—É—î –≤—ñ–¥–ø–æ–≤—ñ–¥—å

        Args:
            vector_store: Vector store –¥–ª—è –ø–æ—à—É–∫—É
            question: –ó–∞–ø–∏—Ç–∞–Ω–Ω—è

        Returns:
            Dict –∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        """
        # –ü–æ—à—É–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç—ñ–≤
        search_start = time.time()
        results_with_scores = vector_store.search_with_scores(question, k=self.config.TOP_K)
        search_time = time.time() - search_start

        # –í–∏—Ç—è–≥—É—î–º–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∏ —Ç–∞ scores
        contexts = []
        scores = []
        for doc, score in results_with_scores:
            contexts.append(doc.page_content)
            scores.append(score)

        # –ì–µ–Ω–µ—Ä—É—î–º–æ –≤—ñ–¥–ø–æ–≤—ñ–¥—å
        context_text = "\n\n".join(contexts)
        prompt = f"""Based on the following context, answer the question.

Context:
{context_text}

Question: {question}

Answer:"""

        generation_start = time.time()
        response = self.llm.invoke(prompt)
        generation_time = time.time() - generation_start

        answer = response.content

        return {
            "question": question,
            "answer": answer,
            "contexts": contexts,
            "scores": scores,
            "avg_score": sum(scores) / len(scores) if scores else 0,
            "search_time_ms": search_time * 1000,
            "generation_time_ms": generation_time * 1000,
            "total_time_ms": (search_time + generation_time) * 1000
        }

    def run_comparison_test(self, questions: List[str] = None) -> Dict[str, Any]:
        """
        –ó–∞–ø—É—Å–∫–∞—î –ø–æ—Ä—ñ–≤–Ω—è–ª—å–Ω–∏–π —Ç–µ—Å—Ç

        Args:
            questions: –°–ø–∏—Å–æ–∫ –∑–∞–ø–∏—Ç–∞–Ω—å (–∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º KUBERNETES_QUESTIONS)

        Returns:
            Dict –∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è
        """
        if questions is None:
            questions = KUBERNETES_QUESTIONS

        print("\n" + "="*80)
        print("üî¨ –ü–û–†–Ü–í–ù–Ø–õ–¨–ù–ï –¢–ï–°–¢–£–í–ê–ù–ù–Ø RAG –°–ò–°–¢–ï–ú")
        print("="*80)
        print(f"\n–ü–∞—Ä–∞–º–µ—Ç—Ä–∏:")
        print(f"  ‚Ä¢ Top-K: {self.config.TOP_K}")
        print(f"  ‚Ä¢ Alpha (MMR): {self.config.ALPHA}")
        print(f"  ‚Ä¢ Chunk size: {self.config.CHUNK_SIZE}")
        print(f"  ‚Ä¢ –ü–∏—Ç–∞–Ω—å: {len(questions)}")
        print(f"\nVector Stores:")
        print(f"  ‚Ä¢ ChromaDB: {self.chromadb.get_collection_count()} –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤")
        print(f"  ‚Ä¢ FAISS: {self.faiss.get_collection_count()} –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤")
        print("\n" + "="*80 + "\n")

        results = {
            "config": {
                "chunk_size": self.config.CHUNK_SIZE,
                "chunk_overlap": self.config.CHUNK_OVERLAP,
                "top_k": self.config.TOP_K,
                "alpha": self.config.ALPHA,
                "llm_model": self.config.LLM_MODEL,
                "timestamp": datetime.now().isoformat()
            },
            "questions": [],
            "summary": {
                "chromadb": {},
                "faiss": {},
                "comparison": {}
            }
        }

        chromadb_times = []
        faiss_times = []
        chromadb_scores = []
        faiss_scores = []

        # –¢–µ—Å—Ç—É—î–º–æ –∫–æ–∂–Ω–µ –ø–∏—Ç–∞–Ω–Ω—è
        for i, question in enumerate(questions, 1):
            print(f"[{i}/{len(questions)}] {question[:60]}...")

            # ChromaDB
            print("   ChromaDB...", end=" ", flush=True)
            chromadb_result = self.retrieve_and_answer(self.chromadb, question)
            print(f"{chromadb_result['total_time_ms']:.0f}ms (score: {chromadb_result['avg_score']:.4f})")

            # FAISS
            print("   FAISS...   ", end=" ", flush=True)
            faiss_result = self.retrieve_and_answer(self.faiss, question)
            print(f"{faiss_result['total_time_ms']:.0f}ms (score: {faiss_result['avg_score']:.4f})")

            # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
            results["questions"].append({
                "question": question,
                "chromadb": chromadb_result,
                "faiss": faiss_result
            })

            # –ó–±–∏—Ä–∞—î–º–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            chromadb_times.append(chromadb_result['total_time_ms'])
            faiss_times.append(faiss_result['total_time_ms'])
            chromadb_scores.append(chromadb_result['avg_score'])
            faiss_scores.append(faiss_result['avg_score'])

            print()

        # –û–±—á–∏—Å–ª—é—î–º–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        results["summary"]["chromadb"] = {
            "avg_time_ms": sum(chromadb_times) / len(chromadb_times),
            "avg_score": sum(chromadb_scores) / len(chromadb_scores),
            "total_time_s": sum(chromadb_times) / 1000
        }

        results["summary"]["faiss"] = {
            "avg_time_ms": sum(faiss_times) / len(faiss_times),
            "avg_score": sum(faiss_scores) / len(faiss_scores),
            "total_time_s": sum(faiss_times) / 1000
        }

        # –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è
        results["summary"]["comparison"] = {
            "speedup_factor": results["summary"]["chromadb"]["avg_time_ms"] / results["summary"]["faiss"]["avg_time_ms"],
            "score_difference": results["summary"]["chromadb"]["avg_score"] - results["summary"]["faiss"]["avg_score"],
            "faster_store": "faiss" if results["summary"]["faiss"]["avg_time_ms"] < results["summary"]["chromadb"]["avg_time_ms"] else "chromadb",
            "better_score": "chromadb" if results["summary"]["chromadb"]["avg_score"] > results["summary"]["faiss"]["avg_score"] else "faiss"
        }

        return results

    def print_summary(self, results: Dict[str, Any]):
        """–í–∏–≤–æ–¥–∏—Ç—å –∑–≤–µ–¥–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤"""
        print("\n" + "="*80)
        print("üìä –ó–í–ï–î–ï–ù–Ü –†–ï–ó–£–õ–¨–¢–ê–¢–ò")
        print("="*80 + "\n")

        chromadb = results["summary"]["chromadb"]
        faiss = results["summary"]["faiss"]
        comp = results["summary"]["comparison"]

        print("CHROMADB:")
        print(f"  ‚Ä¢ –°–µ—Ä–µ–¥–Ω—ñ–π —á–∞—Å –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ: {chromadb['avg_time_ms']:.1f} ms")
        print(f"  ‚Ä¢ –°–µ—Ä–µ–¥–Ω—ñ–π similarity score: {chromadb['avg_score']:.4f}")
        print(f"  ‚Ä¢ –ó–∞–≥–∞–ª—å–Ω–∏–π —á–∞—Å: {chromadb['total_time_s']:.2f} s")

        print("\nFAISS:")
        print(f"  ‚Ä¢ –°–µ—Ä–µ–¥–Ω—ñ–π —á–∞—Å –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ: {faiss['avg_time_ms']:.1f} ms")
        print(f"  ‚Ä¢ –°–µ—Ä–µ–¥–Ω—ñ–π similarity score: {faiss['avg_score']:.4f}")
        print(f"  ‚Ä¢ –ó–∞–≥–∞–ª—å–Ω–∏–π —á–∞—Å: {faiss['total_time_s']:.2f} s")

        print("\n–ü–û–†–Ü–í–ù–Ø–ù–ù–Ø:")
        print(f"  ‚Ä¢ üèÜ –®–≤–∏–¥—à–µ: {comp['faster_store'].upper()} ({comp['speedup_factor']:.2f}x)")
        print(f"  ‚Ä¢ üéØ –ö—Ä–∞—â–∏–π score: {comp['better_score'].upper()}")
        print(f"  ‚Ä¢ üìä –†—ñ–∑–Ω–∏—Ü—è —É score: {abs(comp['score_difference']):.4f}")

        print("\n" + "="*80 + "\n")

    def save_results_to_json(self, results: Dict[str, Any]):
        """–ó–±–µ—Ä—ñ–≥–∞—î –¥–µ—Ç–∞–ª—å–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ —É JSON"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"kubernetes_rag_test_{timestamp}.json"
        filepath = os.path.join(self.config.RESULTS_FOLDER, filename)

        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)

        print(f"‚úì –î–µ—Ç–∞–ª—å–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {filepath}\n")


# ============================================================================
# MAIN
# ============================================================================

def main():
    """–ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è"""

    print("\n" + "="*80)
    print(" "*20 + "üß™ KUBERNETES RAG TESTING")
    print("="*80 + "\n")

    # –°—Ç–≤–æ—Ä—é—î–º–æ —Ç–µ—Å—Ç–µ—Ä
    config = TestConfig()
    tester = RAGKubernetesTester(config)

    # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ PDF –¥–æ–∫—É–º–µ–Ω—Ç–∏
    tester.load_pdfs_to_stores(force_reload=False)

    # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ —î –¥–æ–∫—É–º–µ–Ω—Ç–∏
    if tester.chromadb.get_collection_count() == 0 or tester.faiss.get_collection_count() == 0:
        print("‚ö†Ô∏è  –ù–µ–º–æ–∂–ª–∏–≤–æ –∑–∞–ø—É—Å—Ç–∏—Ç–∏ —Ç–µ—Å—Ç –±–µ–∑ –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤.")
        print(f"   –î–æ–¥–∞–π—Ç–µ Kubernetes PDF –¥–æ–∫—É–º–µ–Ω—Ç–∏ —É –ø–∞–ø–∫—É '{config.PDF_FOLDER}' —Ç–∞ –∑–∞–ø—É—Å—Ç—ñ—Ç—å –∑–Ω–æ–≤—É.\n")
        return

    # –ó–∞–ø—É—Å–∫–∞—î–º–æ –ø–æ—Ä—ñ–≤–Ω—è–ª—å–Ω–∏–π —Ç–µ—Å—Ç
    results = tester.run_comparison_test(KUBERNETES_QUESTIONS)

    # –í–∏–≤–æ–¥–∏–º–æ –∑–≤–µ–¥–µ–Ω–Ω—è
    tester.print_summary(results)

    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –¥–µ—Ç–∞–ª—å–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
    tester.save_results_to_json(results)

    print("="*80)
    print(" "*25 + "‚úì –¢–ï–°–¢ –ó–ê–í–ï–†–®–ï–ù–û")
    print("="*80 + "\n")


if __name__ == "__main__":
    main()
