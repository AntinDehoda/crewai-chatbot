"""
RAG Evaluation Script - –æ—Ü—ñ–Ω–∫–∞ —è–∫–æ—Å—Ç—ñ RAG —Å–∏—Å—Ç–µ–º –∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º ragas
–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î Kubernetes –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—é –∑ –ø–∞–ø–∫–∏ data/pdf/
"""
import os
import time
from datetime import datetime
from typing import List, Dict, Any
from pathlib import Path
from dotenv import load_dotenv
from datasets import Dataset
import pandas as pd

from ragas import evaluate
from ragas.metrics import (
    faithfulness,
    answer_relevancy,
    context_precision,
    context_recall
)

from utils import create_vector_store
from utils.pdf_processor import PDFProcessor
from langchain_openai import ChatOpenAI

load_dotenv()


class RAGEvaluator:
    """–ö–ª–∞—Å –¥–ª—è –æ—Ü—ñ–Ω–∫–∏ —è–∫–æ—Å—Ç—ñ RAG —Å–∏—Å—Ç–µ–º"""

    def __init__(self, vector_store_type: str = "chromadb"):
        """
        –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è RAG Evaluator

        Args:
            vector_store_type: –¢–∏–ø –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Å—Ö–æ–≤–∏—â–∞ ("chromadb" –∞–±–æ "faiss")
        """
        self.vector_store_type = vector_store_type
        self.vector_store = create_vector_store(vector_store_type)
        self.pdf_processor = PDFProcessor()

        # LLM –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –≤—ñ–¥–ø–æ–≤—ñ–¥–µ–π
        self.llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0.7
        )

    def load_documents(self, pdf_paths: List[str]):
        """
        –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î PDF –¥–æ–∫—É–º–µ–Ω—Ç–∏ –¥–æ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Å—Ö–æ–≤–∏—â–∞

        Args:
            pdf_paths: –°–ø–∏—Å–æ–∫ —à–ª—è—Ö—ñ–≤ –¥–æ PDF —Ñ–∞–π–ª—ñ–≤
        """
        print(f"\nüìÑ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤ –¥–æ {self.vector_store_type}...")

        for pdf_path in pdf_paths:
            if not os.path.exists(pdf_path):
                print(f"‚ö†Ô∏è  –§–∞–π–ª –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {pdf_path}")
                continue

            print(f"   –û–±—Ä–æ–±–∫–∞: {pdf_path}")
            chunks = self.pdf_processor.load_pdf(pdf_path)
            self.vector_store.add_documents(chunks)
            print(f"   ‚úì –î–æ–¥–∞–Ω–æ {len(chunks)} chunk'—ñ–≤")

        total_docs = self.vector_store.get_collection_count()
        print(f"\n‚úì –í—Å—å–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤ —É {self.vector_store_type}: {total_docs}\n")

    def retrieve_context(self, query: str, k: int = 4) -> List[str]:
        """
        –í–∏—Ç—è–≥—É—î —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ñ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∏ –¥–ª—è –∑–∞–ø–∏—Ç—É

        Args:
            query: –ó–∞–ø–∏—Ç –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
            k: –ö—ñ–ª—å–∫—ñ—Å—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç—ñ–≤

        Returns:
            List[str]: –°–ø–∏—Å–æ–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç—ñ–≤
        """
        results = self.vector_store.search(query, k=k)
        contexts = [doc.page_content for doc in results]
        return contexts

    def generate_answer(self, query: str, contexts: List[str]) -> str:
        """
        –ì–µ–Ω–µ—Ä—É—î –≤—ñ–¥–ø–æ–≤—ñ–¥—å –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∑–∞–ø–∏—Ç—É —Ç–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç—ñ–≤

        Args:
            query: –ó–∞–ø–∏—Ç –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
            contexts: –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ñ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∏

        Returns:
            str: –ó–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—å
        """
        context_text = "\n\n".join(contexts)

        prompt = f"""–ù–∞ –æ—Å–Ω–æ–≤—ñ –Ω–∞—Å—Ç—É–ø–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –≤—ñ–¥–ø–æ–≤—ñ–¥—å –Ω–∞ –∑–∞–ø–∏—Ç–∞–Ω–Ω—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞.

–ö–æ–Ω—Ç–µ–∫—Å—Ç:
{context_text}

–ó–∞–ø–∏—Ç–∞–Ω–Ω—è: {query}

–í—ñ–¥–ø–æ–≤—ñ–¥—å:"""

        response = self.llm.invoke(prompt)
        return response.content

    def evaluate_rag(
        self,
        test_questions: List[Dict[str, Any]],
        metrics: List = None
    ) -> pd.DataFrame:
        """
        –û—Ü—ñ–Ω—é—î —è–∫—ñ—Å—Ç—å RAG —Å–∏—Å—Ç–µ–º–∏ –∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º ragas

        Args:
            test_questions: –°–ø–∏—Å–æ–∫ —Ç–µ—Å—Ç–æ–≤–∏—Ö –∑–∞–ø–∏—Ç–∞–Ω—å
                –§–æ—Ä–º–∞—Ç: [
                    {
                        "question": "–ø–∏—Ç–∞–Ω–Ω—è",
                        "ground_truth": "–µ—Ç–∞–ª–æ–Ω–Ω–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—å" (–æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ)
                    },
                    ...
                ]
            metrics: –°–ø–∏—Å–æ–∫ –º–µ—Ç—Ä–∏–∫ ragas –¥–ª—è –æ—Ü—ñ–Ω–∫–∏

        Returns:
            pd.DataFrame: –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –æ—Ü—ñ–Ω–∫–∏
        """
        if metrics is None:
            metrics = [
                faithfulness,
                answer_relevancy,
                context_precision,
                context_recall
            ]

        print(f"\nüîç –û—Ü—ñ–Ω–∫–∞ RAG —Å–∏—Å—Ç–µ–º–∏ ({self.vector_store_type})...")
        print(f"   –ö—ñ–ª—å–∫—ñ—Å—Ç—å —Ç–µ—Å—Ç–æ–≤–∏—Ö –∑–∞–ø–∏—Ç–∞–Ω—å: {len(test_questions)}")
        print(f"   –ú–µ—Ç—Ä–∏–∫–∏: {[m.name for m in metrics]}\n")

        # –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö –¥–ª—è –æ—Ü—ñ–Ω–∫–∏
        questions = []
        answers = []
        contexts_list = []
        ground_truths = []

        for i, test_item in enumerate(test_questions, 1):
            question = test_item["question"]
            print(f"   [{i}/{len(test_questions)}] –û–±—Ä–æ–±–∫–∞: {question[:50]}...")

            # –û—Ç—Ä–∏–º—É—î–º–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∏
            contexts = self.retrieve_context(question, k=4)

            # –ì–µ–Ω–µ—Ä—É—î–º–æ –≤—ñ–¥–ø–æ–≤—ñ–¥—å
            answer = self.generate_answer(question, contexts)

            # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –¥–ª—è –æ—Ü—ñ–Ω–∫–∏
            questions.append(question)
            answers.append(answer)
            contexts_list.append(contexts)

            # Ground truth (—è–∫—â–æ —î)
            if "ground_truth" in test_item:
                ground_truths.append(test_item["ground_truth"])
            else:
                ground_truths.append(answer)  # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –∑–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω—É –≤—ñ–¥–ø–æ–≤—ñ–¥—å

        # –°—Ç–≤–æ—Ä—é—î–º–æ dataset –¥–ª—è ragas
        eval_dataset = Dataset.from_dict({
            "question": questions,
            "answer": answers,
            "contexts": contexts_list,
            "ground_truth": ground_truths
        })

        # –í–∏–∫–æ–Ω—É—î–º–æ –æ—Ü—ñ–Ω–∫—É
        print("\n   –í–∏–∫–æ–Ω–∞–Ω–Ω—è –æ—Ü—ñ–Ω–∫–∏ ragas...")
        start_time = time.time()

        result = evaluate(
            eval_dataset,
            metrics=metrics,
            llm=self.llm,
            embeddings=self.vector_store.embeddings
        )

        elapsed_time = time.time() - start_time

        print(f"   ‚úì –û—Ü—ñ–Ω–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {elapsed_time:.2f} —Å–µ–∫—É–Ω–¥\n")

        # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –≤ DataFrame
        results_df = result.to_pandas()

        # –î–æ–¥–∞—î–º–æ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ vector store
        results_df['vector_store'] = self.vector_store_type

        return results_df


def compare_vector_stores(
    pdf_paths: List[str],
    test_questions: List[Dict[str, Any]],
    store_types: List[str] = None
) -> pd.DataFrame:
    """
    –ü–æ—Ä—ñ–≤–Ω—é—î —Ä—ñ–∑–Ω—ñ –≤–µ–∫—Ç–æ—Ä–Ω—ñ —Å—Ö–æ–≤–∏—â–∞

    Args:
        pdf_paths: –°–ø–∏—Å–æ–∫ —à–ª—è—Ö—ñ–≤ –¥–æ PDF —Ñ–∞–π–ª—ñ–≤
        test_questions: –¢–µ—Å—Ç–æ–≤—ñ –∑–∞–ø–∏—Ç–∞–Ω–Ω—è
        store_types: –¢–∏–ø–∏ –≤–µ–∫—Ç–æ—Ä–Ω–∏—Ö —Å—Ö–æ–≤–∏—â –¥–ª—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è

    Returns:
        pd.DataFrame: –ó–≤–µ–¥–µ–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è
    """
    if store_types is None:
        store_types = ["chromadb", "faiss"]

    all_results = []

    for store_type in store_types:
        print(f"\n{'='*60}")
        print(f"–û–¶–Ü–ù–ö–ê: {store_type.upper()}")
        print(f"{'='*60}")

        evaluator = RAGEvaluator(vector_store_type=store_type)

        # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –¥–æ–∫—É–º–µ–Ω—Ç–∏
        evaluator.load_documents(pdf_paths)

        # –û—Ü—ñ–Ω—é—î–º–æ
        results = evaluator.evaluate_rag(test_questions)
        all_results.append(results)

    # –û–±'—î–¥–Ω—É—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
    combined_results = pd.concat(all_results, ignore_index=True)

    return combined_results


def print_comparison_summary(results_df: pd.DataFrame):
    """
    –í–∏–≤–æ–¥–∏—Ç—å –∑–≤–µ–¥–µ–Ω—É —Ç–∞–±–ª–∏—Ü—é –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è

    Args:
        results_df: DataFrame –∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –æ—Ü—ñ–Ω–∫–∏
    """
    print("\n" + "="*60)
    print("–ó–í–ï–î–ï–ù–Ü –†–ï–ó–£–õ–¨–¢–ê–¢–ò –ü–û–†–Ü–í–ù–Ø–ù–ù–Ø")
    print("="*60 + "\n")

    # –í–∏–±–∏—Ä–∞—î–º–æ —Ç—ñ–ª—å–∫–∏ —á–∏—Å–ª–æ–≤—ñ –∫–æ–ª–æ–Ω–∫–∏ (–º–µ—Ç—Ä–∏–∫–∏)
    numeric_cols = results_df.select_dtypes(include=['float64', 'int64', 'float32', 'int32']).columns.tolist()

    # –í–∏–∫–ª—é—á–∞—î–º–æ vector_store —è–∫—â–æ –≤–æ–Ω–∞ —á–∏—Å–ª–æ–≤–∞ (–Ω–µ –ø–æ–≤–∏–Ω–Ω–∞ –±—É—Ç–∏)
    metric_columns = [col for col in numeric_cols if col != 'vector_store']

    if not metric_columns:
        print("‚ö†Ô∏è  –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ —á–∏—Å–ª–æ–≤–∏—Ö –º–µ—Ç—Ä–∏–∫ –¥–ª—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è")
        print(f"   –î–æ—Å—Ç—É–ø–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏: {results_df.columns.tolist()}\n")
        return

    # –ì—Ä—É–ø—É—î–º–æ –ø–æ vector_store —Ç–∞ –æ–±—á–∏—Å–ª—é—î–º–æ —Å–µ—Ä–µ–¥–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è
    summary = results_df.groupby('vector_store')[metric_columns].mean()

    print(summary.to_string())
    print("\n" + "="*60 + "\n")

    # –í–∏–∑–Ω–∞—á–∞—î–º–æ –ø–µ—Ä–µ–º–æ–∂—Ü—è –ø–æ –∫–æ–∂–Ω—ñ–π –º–µ—Ç—Ä–∏—Ü—ñ
    print("üèÜ –ü–ï–†–ï–ú–û–ñ–¶–Ü –ü–û –ú–ï–¢–†–ò–ö–ê–ú:")
    for metric in metric_columns:
        winner = summary[metric].idxmax()
        winner_score = summary.loc[winner, metric]
        print(f"   {metric}: {winner} ({winner_score:.4f})")

    print("\n" + "="*60 + "\n")


def save_summary_to_txt(results_df: pd.DataFrame, output_path: str):
    """
    –ó–±–µ—Ä—ñ–≥–∞—î –∞–Ω–∞–ª—ñ—Ç–∏—á–Ω–µ summary —É TXT —Ñ–∞–π–ª (–±–µ–∑ –ø–æ–≤–Ω–∏—Ö –ø–∏—Ç–∞–Ω—å —Ç–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥–µ–π)

    Args:
        results_df: DataFrame –∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –æ—Ü—ñ–Ω–∫–∏
        output_path: –®–ª—è—Ö –¥–æ –≤–∏—Ö—ñ–¥–Ω–æ–≥–æ TXT —Ñ–∞–π–ª—É
    """
    # –í–∏–±–∏—Ä–∞—î–º–æ —Ç—ñ–ª—å–∫–∏ —á–∏—Å–ª–æ–≤—ñ –∫–æ–ª–æ–Ω–∫–∏ (–º–µ—Ç—Ä–∏–∫–∏)
    numeric_cols = results_df.select_dtypes(include=['float64', 'int64', 'float32', 'int32']).columns.tolist()
    metric_columns = [col for col in numeric_cols if col != 'vector_store']

    if not metric_columns:
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write("‚ö†Ô∏è  –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ —á–∏—Å–ª–æ–≤–∏—Ö –º–µ—Ç—Ä–∏–∫ –¥–ª—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è\n")
        return

    # –ì—Ä—É–ø—É—î–º–æ –ø–æ vector_store —Ç–∞ –æ–±—á–∏—Å–ª—é—î–º–æ —Å–µ—Ä–µ–¥–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è
    summary = results_df.groupby('vector_store')[metric_columns].mean()

    # –§–æ—Ä–º—É—î–º–æ —Ç–µ–∫—Å—Ç –∑–≤—ñ—Ç—É
    lines = []
    lines.append("="*80)
    lines.append(" "*20 + "RAG EVALUATION SUMMARY (RAGAS METRICS)")
    lines.append("="*80)
    lines.append(f"\n–ß–∞—Å –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    lines.append(f"–ö—ñ–ª—å–∫—ñ—Å—Ç—å –ø–∏—Ç–∞–Ω—å –æ—Ü—ñ–Ω–µ–Ω–æ: {len(results_df) // len(summary)}")
    lines.append("\n" + "-"*80)
    lines.append("–°–ï–†–ï–î–ù–Ü –ó–ù–ê–ß–ï–ù–ù–Ø –ú–ï–¢–†–ò–ö")
    lines.append("-"*80 + "\n")

    # –í–∏–≤–æ–¥–∏–º–æ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ vector store
    for store in summary.index:
        lines.append(f"{store.upper()}:")
        for metric in metric_columns:
            value = summary.loc[store, metric]
            lines.append(f"  ‚Ä¢ {metric:25s}: {value:.4f}")
        lines.append("")

    # –í–∏–∑–Ω–∞—á–∞—î–º–æ –ø–µ—Ä–µ–º–æ–∂—Ü—ñ–≤
    lines.append("-"*80)
    lines.append("üèÜ –ü–ï–†–ï–ú–û–ñ–¶–Ü –ü–û –ú–ï–¢–†–ò–ö–ê–ú")
    lines.append("-"*80 + "\n")

    for metric in metric_columns:
        winner = summary[metric].idxmax()
        winner_score = summary.loc[winner, metric]
        loser_score = summary[metric].min()
        diff = winner_score - loser_score
        diff_percent = (diff / loser_score * 100) if loser_score > 0 else 0

        lines.append(f"{metric}:")
        lines.append(f"  Winner: {winner.upper()} ({winner_score:.4f})")
        lines.append(f"  –ü–µ—Ä–µ–≤–∞–≥–∞: +{diff:.4f} (+{diff_percent:.1f}%)")
        lines.append("")

    # –ó–∞–≥–∞–ª—å–Ω—ñ –≤–∏—Å–Ω–æ–≤–∫–∏
    lines.append("-"*80)
    lines.append("–í–ò–°–ù–û–í–ö–ò")
    lines.append("-"*80 + "\n")

    # –ü—ñ–¥—Ä–∞—Ö–æ–≤—É—î–º–æ —Å–∫—ñ–ª—å–∫–∏ –º–µ—Ç—Ä–∏–∫ –≤–∏–≥—Ä–∞–≤ –∫–æ–∂–µ–Ω store
    wins = {}
    for store in summary.index:
        wins[store] = sum(1 for metric in metric_columns if summary[metric].idxmax() == store)

    overall_winner = max(wins.items(), key=lambda x: x[1])
    lines.append(f"–ó–∞–≥–∞–ª—å–Ω–∏–π –ø–µ—Ä–µ–º–æ–∂–µ—Ü—å: {overall_winner[0].upper()}")
    lines.append(f"  –í–∏–≥—Ä–∞–Ω–æ –º–µ—Ç—Ä–∏–∫: {overall_winner[1]}/{len(metric_columns)}")
    lines.append("")

    for store in summary.index:
        lines.append(f"{store}:")
        lines.append(f"  –í–∏–≥—Ä–∞–Ω–æ –º–µ—Ç—Ä–∏–∫: {wins[store]}/{len(metric_columns)}")

    lines.append("\n" + "="*80)
    lines.append("–û–ü–ò–° –ú–ï–¢–†–ò–ö:")
    lines.append("="*80)
    lines.append("‚Ä¢ faithfulness       - –ù–∞—Å–∫—ñ–ª—å–∫–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥—å –±–∞–∑—É—î—Ç—å—Å—è –Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç—ñ (–±–µ–∑ –≥–∞–ª—é—Ü–∏–Ω–∞—Ü—ñ–π)")
    lines.append("‚Ä¢ answer_relevancy   - –ù–∞—Å–∫—ñ–ª—å–∫–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞ –¥–æ –∑–∞–ø–∏—Ç–∞–Ω–Ω—è")
    lines.append("‚Ä¢ context_precision  - –¢–æ—á–Ω—ñ—Å—Ç—å –≤–∏—Ç—è–≥–Ω—É—Ç–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É")
    lines.append("‚Ä¢ context_recall     - –ü–æ–≤–Ω–æ—Ç–∞ –≤–∏—Ç—è–≥–Ω—É—Ç–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É")
    lines.append("="*80 + "\n")

    # –ó–∞–ø–∏—Å—É—î–º–æ —É —Ñ–∞–π–ª
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write('\n'.join(lines))

    print(f"‚úì –ê–Ω–∞–ª—ñ—Ç–∏—á–Ω–µ summary –∑–±–µ—Ä–µ–∂–µ–Ω–æ –≤ {output_path}")


# –ü—Ä–∏–∫–ª–∞–¥ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è
if __name__ == "__main__":
    # Kubernetes —Ç–µ—Å—Ç–æ–≤—ñ –∑–∞–ø–∏—Ç–∞–Ω–Ω—è –∑ ground truth
    test_questions = [
        {
            "question": "What is Kubernetes?",
            "ground_truth": "Kubernetes is an open-source container orchestration platform for automating deployment, scaling, and management of containerized applications."
        },
        {
            "question": "What is a Pod in Kubernetes?",
            "ground_truth": "A Pod is the smallest deployable unit in Kubernetes, representing one or more containers that share network and storage resources."
        },
        {
            "question": "What is the difference between a Pod and a Container?",
            "ground_truth": "A Container is a single application instance, while a Pod can contain one or more tightly coupled containers that share resources and run together on the same node."
        },
        {
            "question": "What is a Deployment in Kubernetes?",
            "ground_truth": "A Deployment is a Kubernetes resource that manages ReplicaSets and provides declarative updates for Pods, enabling rolling updates and rollbacks."
        },
        {
            "question": "What is a Service in Kubernetes?",
            "ground_truth": "A Service is an abstraction that defines a logical set of Pods and a policy for accessing them, providing stable network endpoints for dynamic Pod sets."
        },
        {
            "question": "What are the types of Kubernetes Services?",
            "ground_truth": "The main types are ClusterIP (internal), NodePort (exposes on node port), LoadBalancer (external load balancer), and ExternalName (DNS alias)."
        },
        {
            "question": "What is an Ingress?",
            "ground_truth": "Ingress is a Kubernetes resource that manages external HTTP/HTTPS access to services, providing routing rules, SSL termination, and name-based virtual hosting."
        },
        {
            "question": "How do you perform a rolling update?",
            "ground_truth": "Rolling updates are performed by updating the Deployment specification, which gradually replaces old Pods with new ones while maintaining availability."
        },
        {
            "question": "What are the best practices for managing secrets in Kubernetes?",
            "ground_truth": "Best practices include using Secrets resources, encrypting data at rest, using RBAC for access control, rotating secrets regularly, and considering external secret management tools."
        },
        {
            "question": "How do you implement auto-scaling in Kubernetes?",
            "ground_truth": "Auto-scaling can be implemented using Horizontal Pod Autoscaler (HPA) for scaling Pods based on metrics, and Cluster Autoscaler for scaling nodes."
        },
    ]

    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –∑–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –≤—Å—ñ PDF –∑ –ø–∞–ø–∫–∏ data/pdf/
    pdf_folder = Path("data/pdf")
    if not pdf_folder.exists():
        print("\n" + "="*60)
        print("‚ö†Ô∏è  –ü–ê–ü–ö–ê data/pdf/ –ù–ï –ó–ù–ê–ô–î–ï–ù–ê")
        print("="*60)
        print("\n–°—Ç–≤–æ—Ä—ñ—Ç—å –ø–∞–ø–∫—É data/pdf/ —Ç–∞ –¥–æ–¥–∞–π—Ç–µ —Ç—É–¥–∏ Kubernetes PDF –¥–æ–∫—É–º–µ–Ω—Ç–∏")
        print("\n–ü—Ä–∏–∫–ª–∞–¥ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏:")
        print("   data/pdf/")
        print("       ‚îú‚îÄ‚îÄ kubernetes-basics.pdf")
        print("       ‚îú‚îÄ‚îÄ kubernetes-networking.pdf")
        print("       ‚îî‚îÄ‚îÄ kubernetes-storage.pdf\n")
        exit(1)

    pdf_paths = list(pdf_folder.glob("*.pdf"))

    if not pdf_paths:
        print("\n" + "="*60)
        print("‚ö†Ô∏è  PDF –§–ê–ô–õ–ò –ù–ï –ó–ù–ê–ô–î–ï–ù–û")
        print("="*60)
        print("\n–î–æ–¥–∞–π—Ç–µ Kubernetes PDF –¥–æ–∫—É–º–µ–Ω—Ç–∏ –≤ –ø–∞–ø–∫—É data/pdf/")
        print("\n–†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω—ñ –¥–∂–µ—Ä–µ–ª–∞:")
        print("   - Official Kubernetes documentation exports")
        print("   - Kubernetes in Action (book)")
        print("   - Kubernetes patterns documentation\n")
        exit(1)

    print(f"\nüìö –ó–Ω–∞–π–¥–µ–Ω–æ {len(pdf_paths)} PDF —Ñ–∞–π–ª(—ñ–≤) –≤ data/pdf/:")
    for pdf_path in pdf_paths:
        print(f"   ‚Ä¢ {pdf_path.name}")
    print()

    # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ Path –æ–±'—î–∫—Ç–∏ –≤ —Ä—è–¥–∫–∏
    pdf_paths = [str(p) for p in pdf_paths]

    # –ü–æ—Ä—ñ–≤–Ω—é—î–º–æ –≤–µ–∫—Ç–æ—Ä–Ω—ñ —Å—Ö–æ–≤–∏—â–∞
    results = compare_vector_stores(pdf_paths, test_questions)

    # –í–∏–≤–æ–¥–∏–º–æ –∑–≤–µ–¥–µ–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
    print_comparison_summary(results)

    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –∞–Ω–∞–ª—ñ—Ç–∏—á–Ω–µ summary —É TXT
    os.makedirs("test_results", exist_ok=True)
    save_summary_to_txt(results, "test_results/rag_evaluation_summary.txt")
